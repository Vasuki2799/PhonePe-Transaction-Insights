{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9531ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1cc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated transcation:\n",
    "\n",
    "path1 = \"/Users/arul/Documents/phonepe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "\n",
    "aggr_trans_list = [state for state in os.listdir(path1) if os.path.isdir(os.path.join(path1, state))]\n",
    "\n",
    "columens1 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Transaction_type\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in aggr_trans_list:\n",
    "    current_states = os.path.join(path1, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        A = json.load(data)\n",
    "\n",
    "                        for i in A['data']['transactionData']:\n",
    "                            name = i['name']\n",
    "                            count = i['paymentInstruments'][0]['count']\n",
    "                            amount = i['paymentInstruments'][0]['amount']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens1['Transaction_type'].append(name)\n",
    "                            columens1['Transaction_count'].append(count)\n",
    "                            columens1['Transaction_amount'].append(amount)\n",
    "                            columens1['States'].append(state)\n",
    "                            columens1['Years'].append(year)\n",
    "                            columens1['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b7f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_transaction = pd.DataFrame(columens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7120a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_transaction[\"States\"] = aggregated_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggregated_transaction[\"States\"] = aggregated_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggregated_transaction[\"States\"] = aggregated_transaction[\"States\"].str.title()\n",
    "aggregated_transaction['States'] = aggregated_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424d14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated user:\n",
    "\n",
    "path2 = \"/Users/arul/Documents/phonepe/pulse/data/aggregated/user/country/india/state/\"\n",
    "\n",
    "# List of states in the user data folder\n",
    "aggr_user_list = [state for state in os.listdir(path2) if os.path.isdir(os.path.join(path2, state))]\n",
    "\n",
    "# Columns to store the extracted data\n",
    "columens2 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Brands\": [], \"Count\": [], \"Percentage\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in aggr_user_list:\n",
    "    current_states = os.path.join(path2, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        B = json.load(data)\n",
    "\n",
    "                        # Check if 'usersByDevice' exists\n",
    "                        if not B.get('data', {}).get('usersByDevice'):\n",
    "                            continue  # Skip files with no 'usersByDevice' key\n",
    "\n",
    "                        for i in B['data']['usersByDevice']:\n",
    "                            brand = i['brand']\n",
    "                            count = i['count']\n",
    "                            amount = i['percentage']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens2['Brands'].append(brand)\n",
    "                            columens2['Count'].append(count)\n",
    "                            columens2['Percentage'].append(amount)\n",
    "                            columens2['States'].append(state)\n",
    "                            columens2['Years'].append(year)\n",
    "                            columens2['Quarter'].append(int(file.strip('.json')))\n",
    "                except:\n",
    "                    continue  # Skip files causing any other errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9caa2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_user = pd.DataFrame(columens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f36baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"States\" column to string type\n",
    "aggregated_user[\"States\"] = aggregated_user[\"States\"].astype(str)\n",
    "\n",
    "aggregated_user[\"States\"] = aggregated_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\", \"Andaman & Nicobar\")\n",
    "aggregated_user[\"States\"] = aggregated_user[\"States\"].str.replace(\"-\", \" \")\n",
    "aggregated_user[\"States\"] = aggregated_user[\"States\"].str.title()\n",
    "aggregated_user[\"States\"] = aggregated_user[\"States\"].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2679855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated Insurance:\n",
    "\n",
    "path3 = \"/Users/arul/Documents/phonepe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "\n",
    "# List of states in the insurance data folder\n",
    "aggr_insu_list = [state for state in os.listdir(path3) if os.path.isdir(os.path.join(path3, state))]\n",
    "\n",
    "# Columns to store the extracted data\n",
    "columens3 = {\n",
    "    \"States\": [], \n",
    "    \"Years\": [], \n",
    "    \"Quarter\": [], \n",
    "    \"Transaction_type\": [], \n",
    "    \"Transaction_count\": [], \n",
    "    \"Transaction_amount\": []\n",
    "}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in aggr_insu_list:\n",
    "    current_states = os.path.join(path3, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "        # Iterate through each file\n",
    "        for file in aggr_file_list:\n",
    "            current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "            try:\n",
    "                # Open and read the JSON data\n",
    "                with open(current_file, 'r') as data:\n",
    "                    C = json.load(data)\n",
    "\n",
    "                    # Check if 'transactionData' exists\n",
    "                    transaction_data = C.get('data', {}).get('transactionData', [])\n",
    "                    if not transaction_data:\n",
    "                        # Skip this file if no transactionData exists\n",
    "#                         print(f\"Warning: No transactionData in file {current_file}\")\n",
    "                        continue  # Move to the next file\n",
    "\n",
    "                    # Extract data from each transaction\n",
    "                    for i in transaction_data:\n",
    "                        name = i.get('name', 'Unknown')\n",
    "                        count = i.get('paymentInstruments', [{}])[0].get('count', 0)\n",
    "                        amount = i.get('paymentInstruments', [{}])[0].get('amount', 0)\n",
    "\n",
    "                        # Append data to respective lists\n",
    "                        columens3['Transaction_type'].append(name)\n",
    "                        columens3['Transaction_count'].append(count)\n",
    "                        columens3['Transaction_amount'].append(amount)\n",
    "                        columens3['States'].append(state)\n",
    "                        columens3['Years'].append(year)\n",
    "                        columens3['Quarter'].append(int(file.strip('.json')))\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Log error but continue with the next file\n",
    "                print(f\"JSON Decode Error in file {current_file}: {e}\")\n",
    "                continue  # Skip this file and continue with the next one\n",
    "            except Exception as e:\n",
    "                # Log other errors but continue with the next file\n",
    "                print(f\"Error processing file {current_file}: {e}\")\n",
    "                continue  # Skip this file and continue with the next one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1c7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_insurance = pd.DataFrame(columens3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d83a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_insurance[\"States\"] = aggregated_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "aggregated_insurance[\"States\"] = aggregated_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggregated_insurance[\"States\"] = aggregated_insurance[\"States\"].str.title()\n",
    "aggregated_insurance['States'] = aggregated_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e39f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map transcation:\n",
    "\n",
    "path4 = \"/Users/arul/Documents/phonepe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "\n",
    "map_trans_list = [state for state in os.listdir(path4) if os.path.isdir(os.path.join(path4, state))]\n",
    "\n",
    "columens4 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Districts\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in map_trans_list:\n",
    "    current_states = os.path.join(path4, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        D = json.load(data)\n",
    "\n",
    "                        for i in D['data']['hoverDataList']:\n",
    "                            name = i['name']\n",
    "                            count = i['metric'][0]['count']\n",
    "                            amount = i['metric'][0]['amount']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens4['Districts'].append(name)\n",
    "                            columens4['Transaction_count'].append(count)\n",
    "                            columens4['Transaction_amount'].append(amount)\n",
    "                            columens4['States'].append(state)\n",
    "                            columens4['Years'].append(year)\n",
    "                            columens4['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf591ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_transaction = pd.DataFrame(columens4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e258fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"] = map_transaction[\"States\"].str.title()\n",
    "map_transaction['States'] = map_transaction['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b475c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map user:\n",
    "\n",
    "path5 = \"/Users/arul/Documents/phonepe/pulse/data/map/user/hover/country/india/state/\"\n",
    "\n",
    "map_user_list = [state for state in os.listdir(path5) if os.path.isdir(os.path.join(path5, state))]\n",
    "\n",
    "columens5 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Districts\": [], \"RegisteredUser\": [], \"AppOpens\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in map_user_list:\n",
    "    current_states = os.path.join(path5, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "        # Iterate through each file\n",
    "        for file in aggr_file_list:\n",
    "            current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "            try:\n",
    "                # Open and read the JSON data\n",
    "                with open(current_file, 'r') as data:\n",
    "                    E = json.load(data)\n",
    "\n",
    "                    # Process hoverData items\n",
    "                    hover_data = E.get('data', {}).get('hoverData', {})\n",
    "                    if not hover_data:\n",
    "                        print(f\"Warning: No hoverData in file {current_file}\")\n",
    "                        continue\n",
    "\n",
    "                    for district, details in hover_data.items():\n",
    "                        registereduser = details.get(\"registeredUsers\", 0)\n",
    "                        appOpens = details.get(\"appOpens\", 0)\n",
    "\n",
    "                        # Append data to respective lists\n",
    "                        columens5['Districts'].append(district)\n",
    "                        columens5['RegisteredUser'].append(registereduser)\n",
    "                        columens5['AppOpens'].append(appOpens)\n",
    "                        columens5['States'].append(state)\n",
    "                        columens5['Years'].append(year)\n",
    "                        columens5['Quarter'].append(int(file.strip('.json')))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON Error in file {current_file}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98386ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_user = pd.DataFrame(columens5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e93e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"] = map_user[\"States\"].str.title()\n",
    "map_user['States'] = map_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d868842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map insurance:\n",
    "\n",
    "path6 = \"/Users/arul/Documents/phonepe/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "\n",
    "map_insu_list = [state for state in os.listdir(path6) if os.path.isdir(os.path.join(path6, state))]\n",
    "\n",
    "columens6 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Districts\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in map_insu_list:\n",
    "    current_states = os.path.join(path6, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        F = json.load(data)\n",
    "\n",
    "                        for i in F['data']['hoverDataList']:\n",
    "                            name = i['name']\n",
    "                            count = i['metric'][0]['count']\n",
    "                            amount = i['metric'][0]['amount']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens6['Districts'].append(name)\n",
    "                            columens6['Transaction_count'].append(count)\n",
    "                            columens6['Transaction_amount'].append(amount)\n",
    "                            columens6['States'].append(state)\n",
    "                            columens6['Years'].append(year)\n",
    "                            columens6['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "230b1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_insurance = pd.DataFrame(columens6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9ca7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"] = map_insurance[\"States\"].str.title()\n",
    "map_insurance['States'] = map_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25e1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top transcation:\n",
    "\n",
    "path7 = \"/Users/arul/Documents/phonepe/pulse/data/top/transaction/country/india/state/\"\n",
    "\n",
    "top_trans_list = [state for state in os.listdir(path7) if os.path.isdir(os.path.join(path1, state))]\n",
    "\n",
    "columens7 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in top_trans_list:\n",
    "    current_states = os.path.join(path7, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        G = json.load(data)\n",
    "\n",
    "                        for i in G['data']['pincodes']:\n",
    "                            entityname = i['entityName']\n",
    "                            count = i['metric']['count']\n",
    "                            amount = i['metric']['amount']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens7['Pincodes'].append(entityname)\n",
    "                            columens7['Transaction_count'].append(count)\n",
    "                            columens7['Transaction_amount'].append(amount)\n",
    "                            columens7['States'].append(state)\n",
    "                            columens7['Years'].append(year)\n",
    "                            columens7['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb27ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_transcation = pd.DataFrame(columens7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54d616e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_transcation[\"States\"] = top_transcation[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_transcation[\"States\"] = top_transcation[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transcation[\"States\"] = top_transcation[\"States\"].str.title()\n",
    "top_transcation['States'] = top_transcation['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d814353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top user:\n",
    "\n",
    "path8 = \"/Users/arul/Documents/phonepe/pulse/data/top/user/country/india/state/\"\n",
    "\n",
    "top_user_list = [state for state in os.listdir(path8) if os.path.isdir(os.path.join(path8, state))]\n",
    "\n",
    "columens8 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"RegisteredUser\": [],}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in top_user_list:\n",
    "    current_states = os.path.join(path8, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        H = json.load(data)\n",
    "\n",
    "                        for i in H['data']['pincodes']:\n",
    "                            name = i[\"name\"]\n",
    "                            registeredusers = i[\"registeredUsers\"]\n",
    "                            \n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens8['Pincodes'].append(name)\n",
    "                            columens8['RegisteredUser'].append(registeredusers)\n",
    "                            columens8['States'].append(state)\n",
    "                            columens8['Years'].append(year)\n",
    "                            columens8['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea7aa013",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user = pd.DataFrame(columens8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dd66e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"] = top_user[\"States\"].str.title()\n",
    "top_user['States'] = top_user['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dfc403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top insurance:\n",
    "\n",
    "path9 = \"/Users/arul/Documents/phonepe/pulse/data/top/insurance/country/india/state/\"\n",
    "\n",
    "top_ins_list = [state for state in os.listdir(path9) if os.path.isdir(os.path.join(path9, state))]\n",
    "\n",
    "columens9 = {\"States\": [], \"Years\": [], \"Quarter\": [], \"Pincodes\": [], \"Transaction_count\": [], \"Transaction_amount\": []}\n",
    "\n",
    "# Iterate through the states\n",
    "for state in top_ins_list:\n",
    "    current_states = os.path.join(path9, state)  # Construct state directory path\n",
    "    aggr_year_list = [year for year in os.listdir(current_states) if os.path.isdir(os.path.join(current_states, year))]\n",
    "\n",
    "    # Iterate through the year directories\n",
    "    for year in aggr_year_list:\n",
    "        current_year = os.path.join(current_states, year)  # Construct year directory path\n",
    "\n",
    "        # Get the list of files in the current year directory\n",
    "        if os.path.isdir(current_year):  # Ensure it's a directory\n",
    "            aggr_file_list = [file for file in os.listdir(current_year) if file.endswith(\".json\")]\n",
    "\n",
    "            # Iterate through each file\n",
    "            for file in aggr_file_list:\n",
    "                current_file = os.path.join(current_year, file)  # Full file path\n",
    "\n",
    "                try:\n",
    "                    # Open and read the JSON data\n",
    "                    with open(current_file, 'r') as data:\n",
    "                        J = json.load(data)\n",
    "\n",
    "                        for i in J['data']['pincodes']:\n",
    "                            entityname = i['entityName']\n",
    "                            count = i['metric']['count']\n",
    "                            amount = i['metric']['amount']\n",
    "\n",
    "                            # Append data to respective lists\n",
    "                            columens9['Pincodes'].append(entityname)\n",
    "                            columens9['Transaction_count'].append(count)\n",
    "                            columens9['Transaction_amount'].append(amount)\n",
    "                            columens9['States'].append(state)\n",
    "                            columens9['Years'].append(year)\n",
    "                            columens9['Quarter'].append(int(file.strip('.json')))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {current_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a52fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_insurance = pd.DataFrame(columens9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea51afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.replace(\"andaman-&-nicobar-islands\",\"Andaman & Nicobar\")\n",
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insurance[\"States\"] = top_insurance[\"States\"].str.title()\n",
    "top_insurance['States'] = top_insurance['States'].str.replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0945516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique states\n",
    "unique_states = aggregated_transaction['States'].unique()\n",
    "\n",
    "# Create a new DataFrame with unique states\n",
    "unique_states_df = pd.DataFrame(unique_states, columns=['States'])\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "unique_states_df.to_csv('unique_states.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "723ef954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting DataFrame to csv\n",
    "\n",
    "aggregated_transaction.to_csv('aggregated_transaction.csv',index = False)\n",
    "aggregated_user.to_csv('aggregated_user.csv',index = False)\n",
    "aggregated_insurance.to_csv('aggregated_insurance.csv',index = False)\n",
    "map_transaction.to_csv('map_transaction.csv',index = False)\n",
    "map_user.to_csv('map_user.csv',index = False)\n",
    "map_insurance.to_csv('map_insurance.csv',index = False)\n",
    "top_transcation.to_csv('top_transcation.csv',index = False)\n",
    "top_user.to_csv('top_user.csv',index = False)\n",
    "top_insurance.to_csv('top_insurance.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "335b8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mysql table creation:\n",
    "\n",
    "#Aggregation Transcation\n",
    "\n",
    "\n",
    "# Database configuration\n",
    "\n",
    "config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'xxxxx',\n",
    "    'database': 'phonepe_data_new'\n",
    "}\n",
    "\n",
    "conn = mysql.connector.connect(**config)\n",
    "cursor = conn.cursor()\n",
    " \n",
    "#Insert table\n",
    "\n",
    "create_query_1 = '''CREATE TABLE IF NOT EXISTS aggregated_transaction (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Transaction_Type VARCHAR(255),\n",
    "                    Transaction_Count BIGINT,\n",
    "                    Transaction_Amount BIGINT\n",
    ");\n",
    "'''\n",
    "\n",
    "cursor.execute(create_query_1)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in aggregated_transaction.iterrows():\n",
    "    insert_query_1 = '''INSERT INTO aggregated_transaction (States,\n",
    "                                                            Years,\n",
    "                                                            Quarter,\n",
    "                                                            Transaction_Type,\n",
    "                                                            Transaction_Count,\n",
    "                                                            Transaction_Amount\n",
    "                                                            )\n",
    "\n",
    "                                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Transaction_type'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_1, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91fd4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation User\n",
    "\n",
    "create_query_2 = '''CREATE TABLE IF NOT EXISTS aggregated_user (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Brands VARCHAR(255),\n",
    "                    Count BIGINT,\n",
    "                    Percentage FLOAT\n",
    ");\n",
    "'''\n",
    "\n",
    "cursor.execute(create_query_2)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "for index,row in aggregated_user.iterrows():\n",
    "    insert_query_2 = '''INSERT INTO aggregated_user (States,\n",
    "                                                    Years,\n",
    "                                                    Quarter,\n",
    "                                                    Brands,\n",
    "                                                    Count,\n",
    "                                                    Percentage\n",
    "                                                    )\n",
    "\n",
    "                                        VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Brands'],\n",
    "              row['Count'],\n",
    "              row['Percentage']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_2, values)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c6cf782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Insurance\n",
    "\n",
    "\n",
    "create_query_3 = '''CREATE TABLE IF NOT EXISTS aggregated_insurance (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Transaction_Type VARCHAR(255),\n",
    "                    Transaction_Count BIGINT,\n",
    "                    Transaction_Amount BIGINT\n",
    ");\n",
    "'''\n",
    "\n",
    "cursor.execute(create_query_3)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in aggregated_transaction.iterrows():\n",
    "    insert_query_3 = '''INSERT INTO aggregated_insurance   (States,\n",
    "                                                            Years,\n",
    "                                                            Quarter,\n",
    "                                                            Transaction_Type,\n",
    "                                                            Transaction_Count,\n",
    "                                                            Transaction_Amount\n",
    "                                                            )\n",
    "\n",
    "                                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Transaction_type'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_3, values)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30b35022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Transaction \n",
    "\n",
    "create_query_4 = '''CREATE TABLE IF NOT EXISTS map_transaction (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Districts VARCHAR(255),\n",
    "                    Transaction_Count BIGINT,\n",
    "                    Transaction_Amount FLOAT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_4)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in map_transaction.iterrows():\n",
    "    insert_query_4 = '''INSERT INTO map_transaction (States,\n",
    "                                                    Years,\n",
    "                                                    Quarter,\n",
    "                                                    Districts,\n",
    "                                                    Transaction_Count,\n",
    "                                                    Transaction_Amount\n",
    "                                                    )\n",
    "\n",
    "                                        VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Districts'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_4, values)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7acfaebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map User\n",
    "\n",
    "create_query_5 = '''CREATE TABLE IF NOT EXISTS map_user (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Districts VARCHAR(255),\n",
    "                    RegisteredUser BIGINT,\n",
    "                    AppOpens BIGINT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_5)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in map_user.iterrows():\n",
    "    insert_query_5 = '''INSERT INTO map_user (States,\n",
    "                                            Years,\n",
    "                                            Quarter,\n",
    "                                            Districts,\n",
    "                                            RegisteredUser,\n",
    "                                            AppOpens\n",
    "                                            )\n",
    "\n",
    "                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Districts'],\n",
    "              row['RegisteredUser'],\n",
    "              row['AppOpens']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_5, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a5bfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Insurance \n",
    "\n",
    "create_query_6 = '''CREATE TABLE IF NOT EXISTS map_insurance (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Districts VARCHAR(255),\n",
    "                    Transaction_Count BIGINT,\n",
    "                    Transaction_Amount FLOAT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_6)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in map_insurance.iterrows():\n",
    "    insert_query_6 = '''INSERT INTO map_insurance  (States,\n",
    "                                                    Years,\n",
    "                                                    Quarter,\n",
    "                                                    Districts,\n",
    "                                                    Transaction_Count,\n",
    "                                                    Transaction_Amount\n",
    "                                                    )\n",
    "\n",
    "                                        VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Districts'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_6, values)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c151ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Transaction\n",
    "\n",
    "create_query_7 = '''CREATE TABLE IF NOT EXISTS top_transaction (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Pincodes INT,\n",
    "                    Transaction_count BIGINT,\n",
    "                    Transaction_amount BIGINT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_7)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in top_transcation.iterrows():\n",
    "    insert_query_7 = '''INSERT INTO top_transaction (States,\n",
    "                                                    Years,\n",
    "                                                    Quarter,\n",
    "                                                    Pincodes,\n",
    "                                                    Transaction_count,\n",
    "                                                    Transaction_amount\n",
    "                                                    )\n",
    "\n",
    "                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Pincodes'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_7, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "659daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top User\n",
    "\n",
    "create_query_8 = '''CREATE TABLE IF NOT EXISTS top_user (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Pincodes INT,\n",
    "                    RegisteredUser BIGINT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_8)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in top_user.iterrows():\n",
    "    insert_query_8 = '''INSERT INTO top_user (States,\n",
    "                                            Years,\n",
    "                                            Quarter,\n",
    "                                            Pincodes,\n",
    "                                            RegisteredUser\n",
    "                                            )\n",
    "\n",
    "                                VALUES (%s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Pincodes'],\n",
    "              row['RegisteredUser']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_8, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37fe5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top Insurance\n",
    "\n",
    "create_query_9 = '''CREATE TABLE IF NOT EXISTS top_insurance (\n",
    "                    States VARCHAR(255),\n",
    "                    Years INT,\n",
    "                    Quarter INT,\n",
    "                    Pincodes INT,\n",
    "                    Transaction_count BIGINT,\n",
    "                    Transaction_amount BIGINT\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_query_9)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Insert values in the MySQL table\n",
    "\n",
    "for index,row in top_insurance.iterrows():\n",
    "    insert_query_9 = '''INSERT INTO top_insurance (States,\n",
    "                                                    Years,\n",
    "                                                    Quarter,\n",
    "                                                    Pincodes,\n",
    "                                                    Transaction_count,\n",
    "                                                    Transaction_amount\n",
    "                                                    )\n",
    "\n",
    "                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "    values = (row['States'],\n",
    "              row['Years'],\n",
    "              row['Quarter'],\n",
    "              row['Pincodes'],\n",
    "              row['Transaction_count'],\n",
    "              row['Transaction_amount']\n",
    "             )\n",
    "\n",
    "\n",
    "    cursor.execute(insert_query_9, values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85f929d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aggregated_insurance',),\n",
       " ('aggregated_transaction',),\n",
       " ('aggregated_user',),\n",
       " ('map_insurance',),\n",
       " ('map_transaction',),\n",
       " ('map_user',),\n",
       " ('top_insurance',),\n",
       " ('top_transaction',),\n",
       " ('top_user',)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"show tables\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c0265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08333cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35464f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4f23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60af232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d113f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ead289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876d983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c873f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8441d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e3627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307faaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8440f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1ed8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6a7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2690c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68eb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
